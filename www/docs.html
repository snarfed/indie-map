<!DOCTYPE html>
<html>

<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Indie Map: Docs</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="mobile-web-app-capable" content="yes"/>
<link rel="stylesheet" type="text/css" href="style.css" />
</head>

<body id="docs">
<div id="docs-title">
<div id="header">
  <a href="/">Home</a>
  | <a href="https://github.com/snarfed/indie-map">Source</a>
  | <a href="https://indieweb.org/">#IndieWeb</a>
</div>

<div id="title" class="container">
<h1><b><a href="/">Indie Map</a></b> is a public <a href="https://indieweb.org/">IndieWeb</a> social graph and dataset.</h1>
</div>
</div>

<div class="body container">
<div id="docs-body" class="h-entry e-content">

<h1>Docs <!-- Documentation --></h1>

<ul>
<li><a href="#intro">Introduction</a></li>
<li><a href="#social-graph">Social graph</a></li>
  <ul>
  <li><a href="#social-graph-api">API</a></li>
  <li><a href="#social-graph-viz">Interactive visualization</li>
  </ul>
<li><a href="#data-mining">Data mining</a></li>
<li><a href="#crawl">Crawl</a></li>
  <ul>
  <li><a href="#crawl-data">Data</a></li>
  <li><a href="#crawl-methodology">Methodology</a></li>
  <li><a href="#common-crawl">Common Crawl (historical)</a></li>
  </ul>
<li><a href="#sites">Sites included</a></li>
  <ul>
  <li><a href="#notable">Notable sites</a></li>
  <li><a href="#exceptions">Exceptions</a></li>
  </ul>
</ul>


<h2 id="intro">Introduction</h2>

<p>Indie Map is a complete crawl of 2300 of the most active <a href="https://indieweb.org/">IndieWeb</a> sites, sliced and diced and piled up high in a few useful ways:</p>

<ul>
<li>Social graph <a href="/docs.html#api">API</a> and <a href="map.html">interactive map</a>.</li>
<li><a href="/docs.html#dataset">SQL queryable dataset</a> and <a href="http://metabase.indiemap.org/">GUI analytics tool.</a>
<li><a href="docs.html#crawl">Raw crawl data</a> in <a href="http://bibnum.bnf.fr/WARC/">WARC</a> format: <a href="https://github.com/snarfed/indie-map/blob/master/crawl/domains.txt">2300 sites</a>, 5.7M pages, 380GB HTML + <a href="http://microformats.org/wiki/microformats2">mf2</a>.</li>
</ul>

<p>Indie Map is free, <a href="https://github.com/snarfed/indie-map">open source</a>, and placed into the public domain. It may also be used under the <a href="https://creativecommons.org/share-your-work/public-domain/cc0/">CC0 license</a>. Crawled content remains the property of each site's owner and author, and subject to their existing copyrights.</p>

<p>Support Indie Map by <a href="https://opencollective.com/indieweb">donating to the IndieWeb</a>!</p>


<h2 id="social-graph">Social graph</h2>

<h3 id="social-graph-api">API</h3>

<p>You can fetch each site's data and individual social graph, ie other sites it links to and from, by fetching <code>/<em>DOMAIN</em>.json</code> from this site. For example, my own personal web site is <a href="http://www.indiemap.org/snarfed.org.json"><code>http://www.indiemap.org/snarfed.org.json</code></a>.</p>

<p>The links sections in these files are limited to the top 500 linked sites, by score. If there are more, the <code>links_truncated</code> field will be <code>true</code>. You can get the full contents by fetching <code>/full/<em>DOMAIN</em>.json</code>. You can also get just the links to/from the sites within this dataset by fetching <code>/indie/<em>DOMAIN</em>.json</code>.</p>

<p>Links with <code>rel="nofollow"</code> are excluded.</p>

<p>The <code>hcard</code> field is the <a href="">representative h-card</a> from the site's home page, extracted by <a href="https://github.com/kylewm/mf2util">mf2util</a> 0.5.0's <code>representative_hcard()</code>.</p>

<p>The <code>links</code> field is a list of other sites with links to and from this site, ordered by <code>score</code>, a calculated estimate of the connection strength. The formula is <code>ln(links) / ln (max links)</code>, where links is the total number of links to and from the site, <a href="https://github.com/snarfed/indie-map/blob/master/bigquery/make_web.py#L35">weighted by type</a>, and max links is the highest link count across all sites in this site's list. The weights are:</p>

Direction:
<ul>
<li>outbound: 2x</li>
<li>inbound: 1x</li>
</ul>

Microformats2 class:
<ul>
<li><code>u-in-reply-to, u-invitee</code>: 5x</li>
<li><code>u-repost-of, u-quotation-of</code>: 3x</li>
<li><code>u-like-of, u-favorite-of, u-bookmark-of</code>: 2x</li>
<li>other or none: 2x</li>
</ul>

<p>Webmention, Micropub, WebSub, and IndieAuth endpoints are only extracted from the first matching HTML <code>&lt;link&gt;</code> tag, not all, and not from HTTP headers. These bugs may be fixed in the future.</p>


<h3 id="social-graph-viz">Interactive visualization</h3>

<p><a href="/map.html">Click here for an interactive map of the Indie Web social graph</a>, powered by <a href="https://kumu.io/">Kumu</a>. It renders all sites and links, by score, and lets you navigate and filter by connections, type, server, microformats2 classes, protocols supported (e.g. webmention and micropub), and more.</p>

<p><a href="/map.html"><img src="social_graph.jpg" width="990" style="max-width: 100%" /></a></p>


<h2 id="data-mining">Data mining</h2>

<p>The Indie Map dataset is available in Google's <a href="https://cloud.google.com/bigquery/">BigQuery</a> data warehouse, which supports modern Standard SQL queries. The dataset is <a href="https://bigquery.cloud.google.com/dataset/indie-map:indiemap"><code>indie-map:indiemap</code></a>. You'll need a Google account.</p>

There's also a <a href="http://metabase.indiemap.org/public/dashboard/d46209c0-170d-49a7-a50d-8be64b577f36">Metabase dashboard</a> with analytics.

<!--
<p>The dataset consists of two tables, <code>pages</code> and <code>sites</code>. Here are their schemas:</p>

TODO: mention canonical_pages

<h3><code>pages</code></h3>

<table class="schema">
<tr>
  <th>Field name</th>
  <th>Type</th>
  <th>Description</th>
</tr><tr>
  <td>url</td>
  <td>string</td>
  <td></td>
</tr><tr>
  <td>domain</td>
  <td>string</td>
  <td></td>
</tr><tr>
  <td>fetch_time</td>
  <td>timestamp</td>
  <td></td>
</tr><tr>
  <td>headers</td>
  <td>array&lt; <br />&nbsp;
      string name <br />&nbsp;
      string value <br />
      &gt;</td>
  <td>HTTP response headers</td>
</tr><tr>
  <td>html</td>
  <td>string</td>
  <td></td>
</tr><tr>
  <td>mf2</td>
  <td>string</td>
  <td>parsed mf2, JSON encoded</td>
</tr><tr>
  <td>links</td>
  <td>array&lt;<br />&nbsp;
      tag string <br />&nbsp;
      url string <br />&nbsp;
      classes array&lt;string&gt; <br />&nbsp;
      rels array&lt;string&gt; <br />&nbsp;
      inner_html string <br />
      &gt;</td>
  <td>outbound links extracted from <code>a</code> and <code>link</code> tags</td>
</tr><tr>
  <td>mf2_classes</td>
  <td>array&lt;string&gt;</td>
  <td>all mf2 class names present in the page</td>
</tr><tr>
  <td>rels</td>
  <td>array&lt; <br />&nbsp;
      value string <br />&nbsp;
      urls array&lt;string&gt; <br />
      &gt;</td>
  <td>links with <code>rel</code> values</td>
</tr><tr>
  <td>u_urls</td>
  <td>array&lt;string&gt;</td>
  <td>unique top-level mf2 <code>u-url</code>s</td>
</tr>
</table>

<p>The <code>mf2</code> field is generated by <a href="https://github.com/tommorris/mf2py/issues">mf2py</a> 1.0.5. You can query it in BiqQuery with <a href="https://cloud.google.com/bigquery/docs/reference/legacy-sql#json_extract"><code>JSON_EXTRACT</code></a> and <a href="https://code.google.com/p/jsonpath">JSONPath</a>.</p>


links_out 	INTEGER 	NULLABLE 	
links_in 	INTEGER 	NULLABLE 	
endpoints 	RECORD 	NULLABLE 	
endpoints.token 	STRING 	REPEATED 	
endpoints.authorization 	STRING 	REPEATED 	
endpoints.micropub 	STRING 	REPEATED 	
endpoints.websub 	STRING 	REPEATED 	
endpoints.generator 	STRING 	REPEATED 	
endpoints.webmention 	STRING 	REPEATED 	
tags 	STRING 	REPEATED 	
servers 	STRING 	REPEATED 	
total_html_size 	INTEGER 	NULLABLE 	
domain 	STRING 	NULLABLE 	
names 	STRING 	REPEATED 	
mf2_classes 	STRING 	REPEATED 	
crawl_end 	TIMESTAMP 	NULLABLE 	
descriptions 	STRING 	REPEATED 	
crawl_start 	TIMESTAMP 	NULLABLE 	
pictures 	STRING 	REPEATED 	
hcard 	STRING 	NULLABLE 	
urls 	STRING 	REPEATED 	
rel_mes 	STRING 	REPEATED 	
num_pages 	INTEGER 	NULLABLE 	

<h3><code>sites</code></h3>
<ul>
<tr><td>domain</code></li>
<tr><td>title</code></li>
<li>Open Graph data: <code><meta property="og:...">...</code></li>
<li>rel links: micropub, webmention, authorization_endpoint</li>
<li>rel-me links</li>
<li>authorship: <a href="http://microformats.org/wiki/h-card#Properties"><code>h-card</code></a></li>
<tr><td>p-name</code></li>
<tr><td>u-photo</code> or <code>u-logo</code></li>
<tr><td>u-url</code></li>
<tr><td>p-label</code></li>
<li>social graph</li>
<li>other domains ranked by outbound links, by domain scored by type. maybe reply more then like, outbound more than inbound comment, etc.</li>
<li>special case silos to include username in links</li>
<li>fetch start/end timestamps</li>
<li># of pages crawled</li>
<li># of canonical pages</li>
<li>total html size?</li>
<li>server (best guess)</li>
<li>all mf2 classes seen</li>
<li>webmention endpoints</li>
<li>micropub endpoints</li>
<li>source: bridgy, wm.io, irc people, 2017 iws, other</li>
<li>pagerank?</li>
</ul>

links
from_url 	STRING 	NULLABLE
from_domain 	STRING 	NULLABLE
to_url 	STRING 	NULLABLE
to_domain 	STRING 	NULLABLE
mf2_class 	STRING 	NULLABLE 

links_social_graph
from_domain 	STRING 	NULLABLE
to_domain 	STRING 	NULLABLE
mf2_class 	STRING 	NULLABLE
num 	INTEGER 	NULLABLE
-->


<h2 id="crawl">Crawl</h2>

<h3 id="crawl-data">Data</h3>

<p>The raw crawl data from is available as a set of <a href="http://bibnum.bnf.fr/WARC/">WARC</a> files, one per site, which include full HTTP request and response metadata, headers, and raw response bodies.</p>

<p>The files are stored in <a href="https://cloud.google.com/storage/">Google Cloud Storage</a>, in the <code>gs://indie-map</code> bucket. You can access them for free <a href="https://console.cloud.google.com/storage/browser/indie-map/">via the web UI</a> and the <a href="https://cloud.google.com/storage/docs/quickstart-gsutil"><code>gsutil</code> CLI utility</a>, e.g. <code>gsutil cp gs://indie-map/crawl/<em>DOMAIN</em>.warc.gz</code>. You'll need a Google account.</p>

<p>Individual pages and sites are timestamped. Indie Map may be extended and updated in the future with new crawls.</p>

<h3 id="crawl-methodology">Methodology</h3>

<p>Sites were crawled with with <a href="https://www.gnu.org/software/wget/">GNU <code>wget</code></a> v1.19.1, on Mac OS X 10.11.6 on a mid-2014 MacBook Pro, over a Comcast 100Mbps residential account in San Francisco, <a href="http://metabase.indiemaporg/public/question/e5b392a6-1b30-41a3-ae87-bad03b8bbaac">between April and June 2017</a>. Notable details:</p>

<ul>
<li><a href="http://robotstxt.org/"><code>robots.txt</code> files</a> were respected.</li>
<li><code>wget</code>'s <code>--recursive</code> flag was used to follow links.</li>
<li><code>&lt;a&gt;</code> tags were followed. <code>&lt;link&gt;</code> tags were not followed.</li>
<li>Failed requests due to network connections, etc. were retried 5-10 times.</li>
<li>HTTP requests timed out after 60-120s.</li>
<li>Most sites were crawled at ~.3 <a href="http://en.wikipedia.org/wiki/Queries_per_second">qps</a> to prevent overloading them.</li>
<li>Most HTTP requests used <code>User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:53.0) Gecko/20100101 Firefox/53.0</code>. Requests for some initial sites used <code>User-Agent: Wget/1.19.1</code>.</li>
<li>URLS ending in these file extensions were ignored: <code>as atom avi bz2 bzip bzip2 css csv doc docx dvf epub exe gif GIF gz GZ gzip ico iso jar jpeg JPEG jpg JPG js json m4a m4b m4v mov mp3 mp4 mpg odt ogg pdf PDF png PNG ppt pptx ps rar rdf rss svg swf SWF tar txt text wav wma wmv xml xls xlsx xpi Z zip</code>.</li>
<li><a href="https://github.com/snarfed/indie-map/blob/30a32b6d201ec3326250d4e187a38412d3998e4f/crawl/wget.sh#L8">Other URL patterns were ignored</a> to avoid infinite loop, randomly generated, duplicate, or otherwise low value pages.</li>
<li><code>wget</code>'s <code>--warc-file</code> flag was used to output <a href="http://bibnum.bnf.fr/WARC/">WARC</a> files.</li>
<li>Sent <code>Accept: text/html</code> to <a href="https://rhiaro.co.uk/">rhiaro.co.uk</a> for content negotiation, since it returns RDF by default. Otherwise, didn't send the <code>Accept</code> header to any other sites.
</ul>

<p>Full invocation details in <a href="https://github.com/snarfed/indie-map/blob/master/crawl/wget.sh"><code>wget.sh</code></a>.</p>

<h3 id="common-crawl">Common Crawl (historical)</h3>

<p>I originally tried extracting IndieWeb sites from the <a href="http://commoncrawl.org/">Common Crawl</a>, but it turned out to be too incomplete and sparse. Each individual monthly crawl (averaging 2-3B pages) only includes a handful of sites, and only a handful of pages from those sites. They <a href="https://github.com/commoncrawl/cc-crawl-statistics/blob/master/plots/crawloverlap.md">deliberately spread out the URL space</a>, so I would have needed to process <em>all</em> of their crawls, and even then I probably wouldn't get all pages on the sites I care about.</p>

<p>I considered ignoring domains in a blacklist that I know aren't IndieWeb, e.g. facebook.com and twitter.com. <a href="https://github.com/snarfed/bridgy/blob/master/domain_blacklist.txt">Bridgy's blacklist</a> and the Common Crawl's top 500 domains (<code>s3://commoncrawl/crawl-analysis/CC-MAIN-2017-13/stats/part-00000.gz</code>) were good sources. However, in the March 2017 crawl, those top 500 domains comprise just ~505M of the 3B total pages (ie 1/6), which isn't substantial enough to justify the risk of missing anything.</p>

<p>Related:</p>
<ul>
<li><a href="http://webdatacommons.org/structureddata/#toc1">Web Data Commons</a>: microformats etc</li>
<li><a href="http://manu.sporny.org/2012/structured-data-searching/">Searching for Microformats, RDFa, and Microdata Usage in the Wild</a></li>
<li><a href="http://postneo.com/2011/05/04/social-graph-analysis-using-elastic-mapreduce-and-pypy">Social Graph Analysis using Elastic MapReduce and PyPy</a></li>
<li><a href="https://github.com/iipc/webarchive-commons">webarchive-commons</a></li>
</ul>


<h2 id="sites">Sites included</h2>

<p>Any personal web site is IndieWeb in spirit! <em>Especially</em> if the owner uses it as some or all of their primary personal identity.</p>

<p>For this dataset, I focused on web sites that have interacted with the IndieWeb community in some meaningful way. I tried to include as many of those as I could. The full list is in <a href="https://github.com/snarfed/indie-map/blob/master/crawl/domains.txt"><code>crawl/domains.txt</code></a>, which was compiled from:</p>

<ul>
<li><a href="https://indieweb.org/IRC_People">indieweb.org/IRC_People</a>, as of 2017-04-23.</li>
<li><a href="https://indieweb.org/Special:ListUsers">indieweb.org/Special:ListUsers</a>,ie people who have logged into the IndieWeb wiki, as of 2017-06-09.</li>
<li>Sites <a href="https://webmention.io/">webmention.io</a> has successfully sent at least one webmention to, as of 2017-04-29.</li>
<li>Sites <a href="https://brid.gy/">Bridgy</a> has successfully sent at least one webmention to, as of 2017-04-23.</li>
</ul>

<p>Notable <em>missing</em> collections of sites that we'd love to include:</p>

<ul>
<li>All hosted subdomains under <a href="https://withknown.com/">withknown.com</a>.</li>
<li>All hosted subdomains under <a href="https://micro.blog/">micro.blog</a>.</li>
</ul>

<p>I also propose the modest criteria that a site is IndieWeb in a technical <a href="http://indieweb.org/plumbing">plumbing</a> sense if it has either <a href="http://microformats.org/wiki/microformats2">microformats2</a>, a webmention endpoint, or a micropub endpoint. Indie Map doesn't actually use that criteria anywhere, though.</p>


<h3 id="notable">Notable sites</h3>

<ul>
<li><a href="https://www.museum-digital.de/">museum-digital.de</a>: massive digital catalog of over 34k museum artifacts from 84 museums. Includes h-cards and h-geos for many of the artifacts.</li>
<li><a href="https://huffduffer.com/">huffduffer.com</a>: over 400k podcast links marked up with mf2.</li>
<li><a href="https://www.contrepoints.org/">contrepoints.org</a>: online French newspaper with h-entrys and h-cards.</li>
<li><a href="https://loadaverage.org/">loadaverage.org</a>: fairly big Gnu Social instance with mf2. <a href="https://wiki.loadaverage.org/about">Details.</a></li>
<li><a href="https://wirres.net/">wirres.net</a>: large personal site with over 300k pages.</li>
<li><a href="https://shkspr.mobi/">shkspr.mobi</a>: All of Shakespeare's plays and sonnets, paginated and formatted for mobile.</li>
<li><a href="https://indieweb.org/">indieweb.org</a>, naturally.</li>
<li><a href="https://chat.indieweb.org/">chat.indieweb.org</a>: <a href="https://indieweb.org/discuss">IRC</a> transcripts from #indieweb[camp], #indieweb-dev, #microformats, and more.</li>
<li><a href="https://aaronparecki.com/">aaronparecki.com</a>,
<a href="https://adactio.com/">adactio.com</a>,
<a href="http://caseorganic.com/">caseorganic.com</a>,
<a href="http://crystalbeasley.com/">crystalbeasley.com</a>,
<a href="http://www.kevinmarks.com/">kevinmarks.com</a>,
<a href="http://tantek.com/">tantek.com</a>,
<a href="http://werd.io/">werd.io</a>: IndieWebCamp founders and elders!</li>
</ul>


<h3 id="exceptions">Exceptions</h3>

Sites or parts of sites that were excluded from the dataset.

<ul>
<li><a href="http://achor.net/">achor.net</a>: huge forum site with mf2.</li>
<li><a href="http://adactio.com/extras/talklikeapirate/">adactio.com/extras/talklikeapirate/translate.php</a>: accepts any URL as input, transforms every link in output.</li>
<li><a href="http://airbornesurfer.com/gallery/">airbornesurfer.com/gallery/...</a>: massive set of photo galleries generated by <a href="http://piwigo.org">Piwigo</a>.</li>
<li><a href="http://c2.com/%7Eward/sudokant.cgi">c2.com/~ward/sudokant.cgi</a>: Sudoku solver CGI app, generates sudoku boards forever.</li>
<li><a href="https://chat.indieweb.org/">chat.indieweb.org</a>: pages for single IRC messages, e.g. <code>/????-??-??/...</code>.</li>
<li><a href="http://chriswarbo.net/git/">chriswarbo.net/git/...</a>: web UI to large code repos.</li>
<li><a href="http://cyborganthropology.com/">cyborganthropology.com</a>: MediaWiki special pages, e.g. revision history.</li>
<li><a href="https://dentaku.wazong.de/">dentaku.wazong.de</a>: incomplete, but we do have 98k pages!</li>
<li><a href="http://dev.subversive.audio/agenda">dev.subversive.audio/agenda/...</a>: calendar that navigates into the future forever.</li>
<li><a href="http://dracos.co.uk/made/bbc-news-archive/tardis/search-headline/">dracos.co.uk/made/bbc-news-archive/tardis/search-headline/...</a>: searchable archive of BBC News headlines.</li>
<li><a href="http://fastwonderblog.com/category/ebook/speaking/consulting/speaking/speaking/">fastwonderblog.com/category/.../speaking/consulting/.../</a>: recursive URLs.</li>
<li><a href="http://halfanhour.blogspot.com/search">halfanhour.blogspot.com/search</a>: search UI with infinite loop.</li>
<li><a href="https://huffduffer.com/">huffduffer.com</a>: incomplete. Crawl only found 330k of estimated 410k items and 8k users. Tag and login pages are omitted.</li>
<li><a href="https://indieweb.org/">indieweb.org</a>: pages for single IRC messages, e.g. <code>/irc/????-??-??/line/...</code>.</li>
<li><a href="http://jothut.com/cgi-bin/junco.pl/">jothut.com/cgi-bin/junco.pl/blogpost/...%5C%22http://toledowinter.com/</a> (and toledotalk.com): odd recursive URL mirror.</li>
<li><a href="http://kinderfilmblog.de/">kinderfilmblog.de/?yr=...</a>,</li>
<li><a href="http://kinderfilmblog.de/feed/my-calendar-ics">kinderfilmblog.de/feed/my-calendar-ics?yr=...</a>,</li>
<li><a href="http://kinderfilmblog.de/tolle-kinderfilme/neuerscheinungen-dvd-und-blu-ray/">kinderfilmblog.de/tolle-kinderfilme/neuerscheinungen-dvd-und-blu-ray/?yr=...</a>: infinite loops.</li>
<li><a href="http://kirilind.me/%5C%22/%5C%22/faq/%5C%22/">kirilind.me/%5C%22/%5C%22/faq/%5C%22/...</a>: infinite loop.</li>
<li><a href="http://michael.gorven.za.net/bzr/">michael.gorven.za.net/bzr/...</a>:  web UI to large code repos.</li>
<li><a href="http://nullroute.eu.org/mirrors/shoujoai.com/">nullroute.eu.org/mirrors/shoujoai.com/...</a>: large mirror of another unrelated site.</li>
<!-- <li><a href="http://rhiaro.co.uk/">rhiaro.co.uk</a> defaults response content type to RDF (JSON), not HTML, so I sent it the Accept: text/html HTTP header to use content negotiation and get HTML. That header breaks Known, though, so I didnâ€™t send it to any other sites.</li> -->
<li><a href="http://thecommandline.net/wiki/">thecommandline.net/wiki/...</a>: MediaWiki special pages, e.g. revision history.</li>
<li><a href="http://tilde.club/~odwyer/maze/...">tilde.club/~odwyer/maze/...</a>: random auto-generated maze.</li>
<li><a href="https://unrelenting.technology/git/">unrelenting.technology/git/...</a>: web UI to large code repos.</li>
<li><a href="http://vasilis\.nl/random/daily/.../.*\.svg">vasilis.nl/random/daily/.../*.svg</a>: random generated images.</li>
<li><a href="https://waterpigs.co.uk/mentions/webmention/">waterpigs.co.uk/mentions/webmention/?wmtoken=...</a>: infinite loop, with a new token each time.</li>
<li><a href="https://webdesign.weisshart.de/suchen.php?">webdesign.weisshart.de/suchen.php?...</a>: search results.</li>
<li><a href="http://wiki.projectnerdhaus.com/">wiki.projectnerdhaus.com</a>: MediaWiki special pages (e.g. revision history) are incomplete.</li>
<li><a href="http://www.bakera.de/dokuwiki/doku.php/">www.bakera.de/dokuwiki/...</a>: wiki with lots of query params. Kept actual pages.</li>
<li><a href="http://www.barbic.com.au/">www.barbic.com.au</a>: online shoe store.</li>
<li><a href="http://www.downes.ca/">www.downes.ca</a>: a number of CGI pages that consistently 404ed all URLs: <code>dwiki/?id=...</code> and <code>/cgi-bin/.../*.cgi?...</code></li>
<li><a href="http://www.ogok.de/">www.ogok.de</a>: <code>/search?...</code>, combinatoric explosion of parameter values.</li>
<li><a href="https://www.rmendes.net/">www.rmendes.net/tag/...</a>: incomplete.</li>
<li><a href="http://www.xmlab.org/news/blog-post/">www.xmlab.org/news/blog-post/.../news/blog-post/...</a>: recursive URLs.</li>
</ul>

</div>
</div>
</div>
</div>
</body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-11785301-3', 'auto');
  ga('send', 'pageview');
</script>
</html>
